<div align="center">

<!-- Header Banner -->
<img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=180&section=header&text=Qiang%20Jony%20ZHANG&fontSize=42&fontColor=fff&animation=twinkling&fontAlignY=32&desc=Humanoid%20Robotics%20%7C%20Embodied%20AI%20%7C%20Reinforcement%20Learning&descSize=18&descAlignY=52"/>

<!-- Animated Typing -->
<a href="https://git.io/typing-svg"><img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=600&size=22&pause=1000&color=58A6FF&center=true&vCenter=true&multiline=true&repeat=true&width=600&height=80&lines=%F0%9F%A4%96+Building+the+Future+of+Humanoid+Robots;%F0%9F%A7%A0+Embodied+AI+%7C+RL+%7C+Vision+Perception;%F0%9F%8F%86+Half-Marathon+Champion+%7C+100m+World+Champion" alt="Typing SVG" /></a>

<!-- Social Badges -->
<p>
<a href="https://scholar.google.com/citations?hl=zh-CN&user=9aG3giMAAAAJ&view_op=list_works&sortby=pubdate"><img src="https://img.shields.io/badge/Google%20Scholar-4285F4?style=for-the-badge&logo=google-scholar&logoColor=white" alt="Google Scholar"/></a>
<a href="mailto:jony.zhang@x-humanoid.com"><img src="https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white" alt="Email"/></a>
<a href="mailto:zituka@foxmail.com"><img src="https://img.shields.io/badge/Foxmail-4BA3C3?style=for-the-badge&logo=maildotru&logoColor=white" alt="Foxmail"/></a>
<a href="mailto:qzhang749@connect.hkust-gz.edu.cn"><img src="https://img.shields.io/badge/HKUST--GZ-003366?style=for-the-badge&logo=academia&logoColor=white" alt="HKUST-GZ"/></a>
<img src="https://komarev.com/ghpvc/?username=jonyzhang2023&label=Profile%20Views&color=0e75b6&style=for-the-badge" alt="Profile views"/>
</p>

</div>

---

## ğŸ§‘â€ğŸ”¬ About Me

> **Chair of the Research Committee & Chief Researcher** at the [China National Innovation Center of Embodied AI Robotics](https://x-humanoid.com/)  
> Deeply collaborating with Prof. [Shaoqing Ren](https://shaoqingren.com/) at USTC

- ğŸ¤– Currently leading research on **Humanoid Robots** â€” building the [TianGong Humanoid Robot Platform](https://x-humanoid.com//)
- ğŸ›ï¸ Previously contributed to **"Tianhe å¤©æ²³" Supercomputing** projects and worked at [DJI](https://www.dji.com/)
- ğŸ“ Welcome to visit and apply to our collaborative program at USTC
- ğŸ“š Check out my [Google Scholar](https://scholar.google.com/citations?hl=zh-CN&user=9aG3giMAAAAJ&view_op=list_works&sortby=pubdate) for recent publications
- ğŸ¤ Open to collaborations in **Humanoid Robots, Embodied AI, RL, Vision Perception, LLM, Control & Planning**

### ğŸ¤– Featured Humanoid Projects

<table>
  <tr>
    <td align="center" width="33%">
      <a href="https://x-humanoid.com//">
        <img src="https://img.shields.io/badge/TianGong-Humanoid%20Platform-blue?style=for-the-badge&logo=robot-framework&logoColor=white" alt="TianGong"/>
        <br/><sub><b>China Universal Humanoid Robot Platform</b></sub>
      </a>
    </td>
    <td align="center" width="33%">
      <a href="https://www.youtube.com/watch?v=7hK2ySYBa1I">
        <img src="https://img.shields.io/badge/PNDbotics-Adam-green?style=for-the-badge&logo=youtube&logoColor=white" alt="Adam"/>
        <br/><sub><b>PNDbotics Adam</b></sub>
      </a>
    </td>
    <td align="center" width="33%">
      <a href="https://www.youtube.com/watch?v=kr7FaZPFp6M">
        <img src="https://img.shields.io/badge/Fourier-GR1%20(2021--2023)-orange?style=for-the-badge&logo=youtube&logoColor=white" alt="GR1"/>
        <br/><sub><b>Fourier GR1</b></sub>
      </a>
    </td>
  </tr>
</table>

---

## ğŸ—ï¸ News & Highlights

<!-- Highlight callout -->
> **ğŸ… 2025-08**: We won the **100m championship**, 400m 2nd & 3rd, 1500m 2nd, 4Ã—100m 2nd, material organization championship, and material handling 2nd at [WHR 2025](https://www.whrgoc.com/) â€” the first World Robotics Conference!

> **ğŸƒâ€â™‚ï¸ 2025-04-19**: *The Tiangong humanoid robot made history â€” it successfully completed a **half-marathon**!*

<details>
<summary><b>ğŸ”½ Click to expand full news timeline</b></summary>
<br/>

| Date | Event |
|:-----|:------|
| **2025-11-29** | Our work [SPO](https://arxiv.org/abs/2401.16025) adopted as baseline RL algorithm by [PI0.6](https://www.pi.website/blog/pistar06) |
| **2025-07-29** | Released [Humanoid Occupancy](https://humanoid-occupancy.github.io/) â€” Generalized Multimodal Perception Module |
| **2025-07-09** | Released [TienKung Marathon Control Framework](https://github.com/Open-X-Humanoid/TienKung-Lab) |
| **2025-05-24** | Published an [article in People's Daily](https://www.peopleapp.com/column/30049160906-500006276594) |
| **2025-05-08** | Featured on the "Innovation China" TV program |
| **2025-04-24** | Co-hosted embodied intelligent robots seminar with Peking University |
| **2025-04-10** | Interviewed by "Innovation China" column of China Association for Science and Technology |
| **2025-03-29** | Invited talk at [CEAI 2025](https://ceai.caai.cn/) |
| **2025-03-06** | Joined the CNR Finance Jin Ding Think Tank |
| **2025-01-08** | Participated in Beijing City's long-term robot planning and technical roadmap |
| **2024-12-30** | Invited by National Health Commission as expert reviewer for AI medical projects |
| **2024-11-25** | [Interviewed by Global Times](https://www.globaltimes.cn/page/202411/1323695.shtml) on AI for football & robot marathons |
| **2024-11-16** | Keynote on "Embodied Intelligence of Humanoid Robots" at AGIROS Conference, Chinese Academy of Sciences |
| **2024-11-09** | Intel China Academic Talent Program keynote on "Research on Embodied AI of Humanoid Robots" |
| **2024-11-05** | Attended BAAI "ZhiYuan Forum â€” Embodiment and World Model Summit" |
| **2024-09-30** | Talk at Peking University on Multimodal Perception & Large Model Decision-Making for Humanoid Robots |
| **2024-07-29** | Interviewed by Mango (Hunan) TV on "Embodied AI and Humanoid Robots Tian Gong" |
| **2024-07-05** | Invited by China Internet Research Institute to draft embodied intelligence white paper |
| **2024-07-01** | Invited talk at XMech, Zhejiang University |
| **2024-05-29** | Interviewed by Beijing Association for Science and Technology |
| **2024-05-09** | [Featured on CCTV](https://tv.cctv.com/2024/05/09/VIDEk6Q0pOBAcbsWlM6mD2gN240509.shtml) â€” TianGong continuous iteration |

</details>

---

## ğŸ“ Selected Publications

I'm currently exploring **Embodied AI, RL, Vision Perception, LLM, Control & Planning in Robotics.**

### ğŸ”¬ Pre-prints

<details open>
<summary><b>ğŸ”½ Click to expand pre-prints</b></summary>
<br/>

| Title | Link |
|:------|:----:|
| MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction | [ğŸ”—](https://meshmimic.github.io/) |
| HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model | [ğŸ”—](https://haic-humanoid.github.io/) |
| RoboStriker: Hierarchical Decision-Making for Autonomous Humanoid Boxing | [ğŸ”—](https://www.alphaxiv.org/abs/2601.22517) |
| MVISTA-4D: View-Consistent 4D World Model with Test-Time Action Inference | [ğŸ”—](https://www.alphaxiv.org/abs/2602.09878) |
| DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis | [ğŸ”—](https://arxiv.org/pdf/2510.07152) |
| PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control | [ğŸ”—](https://arxiv.org/pdf/2509.24591) |
| EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation | [ğŸ”—](https://arxiv.org/pdf/2509.22578) |
| HumanoidVerse: A Versatile Humanoid for Vision-Language Guided Multi-Object Rearrangement | [ğŸ”—](https://haozhuo-zhang.github.io/HumanoidVerse-project-page/) |
| LOVON: Legged Open-Vocabulary Object Navigator | [ğŸ”—](https://arxiv.org/abs/2507.06747) |
| Survival Games: Human-LLM Strategic Showdowns under Severe Resource Scarcity | [ğŸ”—](https://arxiv.org/abs/2505.17937) |
| Occupancy World Model for Robots | [ğŸ”—](https://www.arxiv.org/abs/2505.05512) |
| RoboOcc: Enhancing the Geometric and Semantic Scene Understanding for Robots | [ğŸ”—](https://arxiv.org/pdf/2504.14604) |
| The Meta-Representation Hypothesis | [ğŸ”—](https://arxiv.org/abs/2501.02481) |
| EmbodiedVSR: Dynamic Scene Graph-Guided Chain-of-Thought Reasoning for Visual Spatial Tasks | [ğŸ”—](https://arxiv.org/abs/2503.11089) |
| HumanoidPano: Hybrid Spherical Panoramic-LiDAR Cross-Modal Perception for Humanoid Robots | [ğŸ”—](https://arxiv.org/abs/2503.09010) |
| NeuGPT: Unified multi-modal Neural GPT | [ğŸ”—](https://arxiv.org/pdf/2410.20916) |
| Recursive Cleaning for Large-scale Protein Data via Multimodal Learning | [ğŸ”—](https://www.biorxiv.org/content/biorxiv/early/2024/10/12/2024.10.08.617190.full.pdf) |
| Query-based Semantic Gaussian Field for Scene Representation in RL | [ğŸ”—](https://arxiv.org/pdf/2406.02370) |
| Mamba as Decision Maker: Exploring Multi-scale Sequence Modeling in Offline RL | [ğŸ”—](https://arxiv.org/pdf/2406.02013) |
| MAD: Multi-Alignment MEG-to-Text Decoding | [ğŸ”—](https://arxiv.org/abs/2406.01512) |
| Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End VLA Models | [ğŸ”—](https://arxiv.org/pdf/2409.13174) |
| E2H: A Two-Stage Non-Invasive Neural Signal Driven Humanoid Robotic Whole-Body Control | [ğŸ”—](https://arxiv.org/abs/2410.02141) |
| Typography Leads Semantic Diversifying: Amplifying Adversarial Transferability across MLLMs | [ğŸ”—](https://arxiv.org/abs/2405.20090) |
| A Dual-Agent Adversarial Framework for Robust Generalization in Deep RL | [ğŸ”—](https://arxiv.org/pdf/2501.17384) |

</details>

### ğŸ“„ Peer-Reviewed Publications

<details open>
<summary><b>ğŸ”½ Click to expand publications</b></summary>
<br/>

| Venue | Title | Link |
|:------|:------|:----:|
| **IROS 2024** | Whole-body Humanoid Robot Locomotion with Human Reference | [ğŸ”—](https://arxiv.org/abs/2402.18294) |
| **CVPR 2026** | SwiftVLA: Unlocking Spatiotemporal Dynamics for Lightweight VLA Models | [ğŸ”—](https://arxiv.org/abs/2512.00903) |
| **ICLR 2026** | Compose Your Policies! Improving Diffusion/Flow Robot Policies via Test-time Composition | [ğŸ”—](https://arxiv.org/pdf/2510.01068) |
| **ICLR 2026** | ArtVIP: Articulated Digital Assets for Robot Learning | [ğŸ”—](https://www.arxiv.org/abs/2506.04941) |
| **ICRA 2026** | Physics-informed Diffusion Mamba Transformer for Real-world Driving | ğŸ“¬ |
| **ICRA 2026** | TopoNav: Topological Graphs as a Key Enabler for Advanced Object Navigation | [ğŸ”—](https://arxiv.org/pdf/2509.01364) |
| **ICRA 2026** | Learning Structural Latent Points for Efficient Visual Representations in Robotic Manipulation | ğŸ“¬ |
| **AAAI 2026** | What You See is What You Reach: Spatial Navigation with High-Level Human Instructions | [ğŸ”—](https://openreview.net/pdf?id=ow65qpDY3Q) |
| **ICASSP 2026** | NeuSpeech: Decode Neural Signal as Speech | [ğŸ”—](https://arxiv.org/pdf/2403.01748v3) |
| **ICML 2025** | Simple Policy Optimization | [ğŸ”—](https://arxiv.org/abs/2401.16025) |
| **RSS 2025** | RoboMIND: Benchmark on Multi-embodiment Intelligence Normative Data for Robot Manipulation | [ğŸ”—](https://arxiv.org/pdf/2412.13877) |
| **IEEE TVCG** | DEGS: Deformable Event-based 3D Gaussian Splatting | [ğŸ”—](https://openreview.net/pdf?id=gSO9fYLPSw) |
| **CoRL 2025** | Omni-Perception: Omnidirectional Collision Avoidance for Legged Locomotion | [ğŸ”—](https://acodedog.github.io/OmniPerceptionPages/) |
| **ICCV 2025** | What Makes for Text to 360-degree Panorama Generation with Stable Diffusion? | [ğŸ”—](https://huggingface.co/papers/2505.22129) |
| **ICCV 2025** | Learning Null Geodesics for Gravitational Lensing Rendering in General Relativity | [ğŸ”—](https://openreview.net/forum?id=2syCDlDdtB) |
| **ACMMM 2025** | Transfer Attack for Bad and Good: Adversarial Transferability across MLLMs | [ğŸ”—](https://openreview.net/forum?id=F6UY0u0Hxd#discussion) |
| **IROS 2025** | Mamba Policy: Towards Efficient 3D Diffusion Policy with Hybrid Selective State Models | [ğŸ”—](https://www.arxiv.org/pdf/2409.07163) |
| **IROS 2025** | Distillation-PPO: Two-Stage RL Framework for Humanoid Perceptive Locomotion | [ğŸ”—](https://arxiv.org/abs/2503.08299) |
| **ACL 2025** | MapNav: Novel Memory Representation via Annotated Semantic Maps for VLN | [ğŸ”—](https://arxiv.org/abs/2502.13451) |
| **CVPR 2025** | Uncovering Vision Modality Threats in Image-to-Image Tasks | [ğŸ”—](https://arxiv.org/pdf/2412.05538) |
| **ICRA 2025** | Multi-Floor Zero-Shot Object Navigation Policy | [ğŸ”—](https://arxiv.org/pdf/2409.10906) |
| **ICASSP 2025** | Fully Spiking Neural Network for Legged Robots | [ğŸ”—](https://arxiv.org/pdf/2310.05022) |
| **ICASSP 2025** | Event Masked Autoencoder: Point-wise Action Recognition | [ğŸ”—](https://arxiv.org/pdf/2501.01040) |
| **ICME 2025** | ES-Parkour: Advanced Robot Parkour with Bio-inspired Event Camera & SNN | [ğŸ”—](https://arxiv.org/abs/2503.09985) |
| **IJCAI 2025** ğŸ† | Exploring Typographic Visual Prompts Injection Threats in Cross-Modality Models | [ğŸ”—](https://arxiv.org/pdf/2503.11519) |
| PM2CE@**IROS 2025** | Humanoid Occupancy: Generalized Multimodal Occupancy Perception for Humanoid Robots | [ğŸ”—](https://humanoid-occupancy.github.io/) |
| H2R@**CoRL 2025** | UniTracker: Universal Whole-Body Motion Tracker for Humanoid Robots | [ğŸ”—](https://yinkangning0124.github.io/Humanoid-UniTracker/) |
| Sim2Real@**Humanoids 2025** | LiPS: Large-Scale Humanoid Robot RL with Parallel-Series Structures | [ğŸ”—](https://arxiv.org/abs/2503.08349) |
| Sim2Real@**Humanoids 2025** | Trinity: A Modular Humanoid Robot AI System | [ğŸ”—](https://arxiv.org/abs/2503.08338) |
| GenModels@**ICLR 2025** | Modality-Composable Diffusion Policy via Distribution-level Composition | [ğŸ”—](https://github.com/AndyCao1125/MCDP) |
| **NeurIPS 2024** | DEL: Discrete Element Learner for Learning 3D Dynamics from 2D Observations | [ğŸ”—](https://openreview.net/forum?id=2nvkD0sPOk) |
| **NeurIPS 2024** | Spiking Neural Network as Adaptive Event Stream Slicer | [ğŸ”—](https://openreview.net/forum?id=CcNw4mVIxo) |
| **IEEE TAI** | Spiking Diffusion Models | [ğŸ”—](https://arxiv.org/pdf/2408.16467) |
| **IROS 2024** | Reinforcement Learning with Generalizable Gaussian Splatting | [ğŸ”—](https://arxiv.org/pdf/2404.07950) |
| **IROS 2024** | TriHelper: Zero-Shot Object Navigation with Dynamic Assistance | [ğŸ”—](https://arxiv.org/pdf/2403.15223) |
| **ICRA 2024** | Prompting Multi-Modal Tokens for End-to-End Autonomous Driving with LLMs | [ğŸ”—](https://arxiv.org/pdf/2404.04869) |
| **ICRA 2024** | Prompt, Plan, Perform: LLM-based Humanoid Control via Quantized Imitation Learning | [ğŸ”—](https://arxiv.org/abs/2309.11359) |
| **WACV 2024** | Spiking Denoising Diffusion Probabilistic Models | [ğŸ”—](https://arxiv.org/abs/2306.17046) |
| **ICCV 2023** | Masked Spiking Transformer | [ğŸ”—](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Masked_Spiking_Transformer_ICCV_2023_paper.pdf) |
| **CoRL 2022** | RoboTube: Learning Household Manipulation from Human Videos | [ğŸ”—](https://research.nvidia.com/labs/srl/publication/xiong-2022-robo-tube/) |

</details>

> ğŸ’¡ *I have hidden some previous work â€” feel free to chat! Currently preparing my personal website.*

---

## ğŸ’» Tech Stack

<div align="center">
<table>
  <tr>
    <td align="center" width="96">
      <a href="#"><img src="https://techstack-generator.vercel.app/python-icon.svg" alt="icon" width="65" height="65" /></a>
      <br>Python
    </td>
    <td align="center" width="96">
      <img src="https://techstack-generator.vercel.app/cpp-icon.svg" alt="icon" width="65" height="65" />
      <br>C++
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=c" width="48" height="48" alt="C" />
      <br>C
    </td>
    <td align="center" width="96">
      <img src="https://techstack-generator.vercel.app/js-icon.svg" alt="icon" width="65" height="65" />
      <br>JavaScript
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=r" width="48" height="48" alt="R" />
      <br>R
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=bash" width="48" height="48" alt="Bash" />
      <br>Bash
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=matlab" width="48" height="48" alt="MATLAB" />
      <br>MATLAB
    </td>
  </tr>
  <tr>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=pytorch" width="48" height="48" alt="PyTorch" />
      <br>PyTorch
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=tensorflow" width="48" height="48" alt="TensorFlow" />
      <br>TensorFlow
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=opencv" width="48" height="48" alt="OpenCV" />
      <br>OpenCV
    </td>
    <td align="center" width="96">
      <img src="https://techstack-generator.vercel.app/docker-icon.svg" alt="icon" width="65" height="65" />
      <br>Docker
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=linux" width="48" height="48" alt="Linux" />
      <br>Linux
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=ubuntu" width="48" height="48" alt="Ubuntu" />
      <br>Ubuntu
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=redhat" width="48" height="48" alt="RedHat" />
      <br>RedHat
    </td>
  </tr>
  <tr>
    <td align="center" width="96">
      <img src="https://techstack-generator.vercel.app/github-icon.svg" alt="icon" width="65" height="65" />
      <br>GitHub
    </td>
    <td align="center" width="96">
      <img src="https://user-images.githubusercontent.com/25181517/192108372-f71d70ac-7ae6-4c0d-8395-51d8870c2ef0.png" width="48" height="48" alt="Git" />
      <br>Git
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=gitlab" width="48" height="48" alt="GitLab" />
      <br>GitLab
    </td>
    <td align="center" width="96">
      <img src="https://techstack-generator.vercel.app/aws-icon.svg" alt="icon" width="65" height="65" />
      <br>AWS
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=cmake" width="48" height="48" alt="CMake" />
      <br>CMake
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=jenkins" width="48" height="48" alt="Jenkins" />
      <br>Jenkins
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=raspberrypi" width="48" height="48" alt="RPi" />
      <br>RPi
    </td>
  </tr>
  <tr>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=vscode" width="48" height="48" alt="VSCode" />
      <br>VSCode
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=pycharm" width="48" height="48" alt="PyCharm" />
      <br>PyCharm
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=vim" width="48" height="48" alt="Vim" />
      <br>Vim
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=sublime" width="48" height="48" alt="Sublime" />
      <br>Sublime
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=html" width="48" height="48" alt="HTML5" />
      <br>HTML5
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=ps" width="48" height="48" alt="PS" />
      <br>PS
    </td>
    <td align="center" width="96">
      <img src="https://skillicons.dev/icons?i=ai" width="48" height="48" alt="AI" />
      <br>AI
    </td>
  </tr>
</table>
</div>

---

## ğŸ“Š GitHub Stats

<div align="center">

<a href="https://github.com/jonyzhang2023?tab=repositories">
  <img src="https://github-readme-stats-one-bice.vercel.app/api?username=jonyzhang2023&theme=tokyonight&show_icons=true&count_private=true&hide_border=true&role=OWNER,ORGANIZATION_MEMBER,COLLABORATOR" width="49%" alt="GitHub Stats"/>
</a>
<a href="https://github.com/jonyzhang2023?tab=repositories">
  <img src="https://github-readme-streak-stats.herokuapp.com/?user=jonyzhang2023&theme=tokyonight&hide_border=true" width="49%" alt="GitHub Streak"/>
</a>

<br/>

<a href="https://wakatime.com/@jonyzhang20238888">
  <img src="https://github-readme-activity-graph.vercel.app/graph?username=jonyzhang2023&theme=tokyo-night&hide_border=true&hide_title=false&area=true&custom_title=Total%20contribution%20graph%20in%20all%20repo" width="98%" alt="Activity Graph">
</a>

</div>

---

<div align="center">

<!-- Snake Animation -->
<picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/jonyzhang2023/jonyzhang2023/output/github-snake-dark.svg" />
  <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/jonyzhang2023/jonyzhang2023/output/github-snake.svg" />
  <img alt="github-snake" src="https://raw.githubusercontent.com/jonyzhang2023/jonyzhang2023/output/github-snake.svg" />
</picture>

</div>

<!-- Footer -->
<img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=100&section=footer"/>
